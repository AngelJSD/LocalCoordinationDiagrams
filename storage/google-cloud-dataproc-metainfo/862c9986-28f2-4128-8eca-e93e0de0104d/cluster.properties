#Cluster properties
#Sat Oct 12 08:07:31 PDT 2019
mapred-env\:HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1920
hdfs\:dfs.datanode.address=0.0.0.0\:9866
hdfs\:dfs.datanode.http.address=0.0.0.0\:9864
spark\:spark.executor.memory=2688m
mapred\:mapreduce.task.io.sort.mb=256
spark\:spark.yarn.am.memory=640m
distcp\:mapreduce.map.memory.mb=768
mapred\:mapreduce.reduce.cpu.vcores=1
dataproc\:dataproc.control.task.stream.duration.sec=900
yarn\:yarn.nodemanager.resource.memory-mb=6144
spark\:spark.executorEnv.OPENBLAS_NUM_THREADS=1
core\:fs.gs.block.size=134217728
yarn\:yarn.scheduler.maximum-allocation-mb=6144
hdfs\:dfs.namenode.http-address=0.0.0.0\:9870
mapred\:yarn.app.mapreduce.am.resource.mb=2048
dataproc\:dataproc.heartbeat.master.frequency.sec=30
mapred\:mapreduce.reduce.java.opts=-Xmx1638m
distcp\:mapreduce.reduce.memory.mb=768
dataproc\:dataproc.control.task.request.interval.millis=5000
spark-env\:SPARK_DAEMON_MEMORY=1920m
dataproc\:dataproc.scheduler.max-memory-used=0.9
yarn\:yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs=86400
yarn\:yarn.scheduler.minimum-allocation-mb=512
spark\:spark.executor.instances=2
dataproc\:dataproc.scheduler.max-concurrent-jobs=5
hdfs\:dfs.datanode.ipc.address=0.0.0.0\:9867
hdfs\:dfs.namenode.service.handler.count=10
core\:fs.gs.metadata.cache.enable=false
mapred\:mapreduce.map.java.opts=-Xmx1638m
hdfs\:dfs.namenode.servicerpc-address=cluster-f32d-m\:8051
spark\:spark.driver.memory=1920m
dataproc\:am.primary_only=false
dataproc\:dataproc.heartbeat.worker.frequency.sec=-1
mapred\:mapreduce.reduce.memory.mb=2048
mapred\:yarn.app.mapreduce.am.command-opts=-Xmx1638m
hdfs\:dfs.namenode.https-address=0.0.0.0\:9871
dataproc\:dataproc.conscrypt.provider.enable=true
hdfs\:dfs.namenode.handler.count=20
mapred\:mapreduce.map.cpu.vcores=1
distcp\:mapreduce.map.java.opts=-Xmx576m
spark\:spark.executor.cores=1
hdfs\:dfs.namenode.lifeline.rpc-address=cluster-f32d-m\:8050
hdfs\:dfs.namenode.secondary.http-address=0.0.0.0\:9868
dataproc\:dataproc.monitoring.stackdriver.enable=false
mapred\:mapreduce.job.maps=15
dataproc\:dataproc.control.task.invalidation.interval.millis=5000
core\:hadoop.ssl.enabled.protocols=TLSv1,TLSv1.1,TLSv1.2
spark\:spark.driver.maxResultSize=960m
dataproc\:agent.spark.driver.empty.jar=true
distcp\:mapreduce.reduce.java.opts=-Xmx576m
mapred\:yarn.app.mapreduce.am.resource.cpu-vcores=1
mapred\:mapreduce.job.reduce.slowstart.completedmaps=0.95
hdfs\:dfs.namenode.secondary.https-address=0.0.0.0\:9869
capacity-scheduler\:yarn.scheduler.capacity.root.default.ordering-policy=fair
mapred\:mapreduce.map.memory.mb=2048
spark\:spark.sql.cbo.enabled=true
mapred\:mapreduce.job.reduces=5
spark\:spark.scheduler.mode=FAIR
hdfs\:dfs.datanode.https.address=0.0.0.0\:9865
yarn-env\:YARN_TIMELINESERVER_HEAPSIZE=1920
